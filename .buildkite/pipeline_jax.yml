steps:
  # -----------------------------------------------------------------
  # TEST STEPS - Calling wrapper
  # -----------------------------------------------------------------
   - label: "E2E MLPerf tests for JAX models"
     key: test_0
     soft_fail: true
     agents:
       queue: tpu_v6e_queue
     commands:
       - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

   - label: "E2E MLPerf tests for JAX models with quantization"
     key: test_1
     soft_fail: true
     env:
       QUANTIZATION: "True"
     agents:
       queue: tpu_v6e_queue
     commands:
       - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

   - label: "E2E MLPerf tests for JAX new models"
     key: test_2
     soft_fail: true
     env:
       NEW_MODEL_DESIGN: "True"
     agents:
       queue: tpu_v6e_queue
     commands:
       - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

   - label: "E2E MLPerf tests for JAX + vLLM models on single chip"
     key: test_3
     soft_fail: true
     env:
       MODEL_IMPL_TYPE: "vllm"
     agents:
       queue: tpu_v6e_queue
     commands:
       - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

   - label: "E2E MLperf tests for Llama4 models"
     key: test_4
     soft_fail: true
     env:
       NEW_MODEL_DESIGN: "True"
       USE_V6E8_QUEUE: "True"
     agents:
       queue: tpu_v6e_8_queue
     commands:
       - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh


   - label: "E2E multi modality test"
     key: test_5
     soft_fail: true
     agents:
       queue: tpu_v6e_queue
     commands:
       - |
         .buildkite/scripts/run_in_docker.sh \
           bash -c 'python3 -m pytest -s -v -x /workspace/tpu_inference/tests/e2e/test_multi_modal_inference.py && \
            bash /workspace/tpu_inference/tests/e2e/benchmarking/mm_bench.sh'

   - label: "E2E speculative decoding test"
     key: test_6
     soft_fail: true
     agents:
       queue: tpu_v6e_queue
     commands:
       - |
         .buildkite/scripts/run_in_docker.sh \
           bash -c 'python3 -m pytest -s -v -x /workspace/tpu_inference/tests/e2e/test_speculative_decoding.py'

   - label: "JAX unit tests"
     key: test_7
     soft_fail: true
     agents:
       queue: tpu_v6e_queue
     commands:
       - |
         .buildkite/scripts/run_in_docker.sh \
           python3 -m pytest -s -v -x /workspace/tpu_inference/tests/ \
           --ignore=/workspace/tpu_inference/tests/kernels \
           --ignore=/workspace/tpu_inference/tests/lora \
           --ignore=/workspace/tpu_inference/tests/e2e \
           --ignore=/workspace/tpu_inference/tpu_inference/mock \
           --cov-config=/workspace/tpu_inference/.coveragerc --cov tpu_inference --cov-report term-missing --cov-fail-under=69

   - label: "JAX unit tests - kernels"
     key: test_8
     soft_fail: true
     agents:
       queue: tpu_v6e_queue
     commands:
       - |
         .buildkite/scripts/run_in_docker.sh \
           python3 -m pytest -s -v -x /workspace/tpu_inference/tests/kernels \
           --ignore=/workspace/tpu_inference/tests/kernels/ragged_paged_attention_kernel_v2_test.py \
           --ignore=/workspace/tpu_inference/tests/kernels/ragged_kv_cache_update_v2_test.py \
           --ignore=/workspace/tpu_inference/tests/kernels/collectives

   - label: "JAX unit tests - collective kernels"
     key: test_9
     soft_fail: true
     agents:
       queue: tpu_v6e_8_queue
     commands:
       - |
         .buildkite/scripts/run_in_docker.sh \
           python3 -m pytest -s -v -x /workspace/tpu_inference/tests/kernels/collectives

   - label: "lora tests for JAX + vLLM models single chip"
     key: test_10
     soft_fail: true
     agents:
       queue: tpu_v6e_queue
     commands:
       - |
         .buildkite/scripts/run_in_docker.sh \
           bash -c 'MODEL_IMPL_TYPE=vllm TPU_BACKEND_TYPE=jax python3 -m pytest -s -v -x /workspace/tpu_inference/tests/lora/test_lora.py'

   - label: "E2E MLPerf tests for JAX + vLLM models on multiple chips"
     key: test_11
     soft_fail: true
     env:
       MODEL_IMPL_TYPE: "vllm"
     agents:
       queue: tpu_v6e_8_queue
     commands:
       - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

   - label: "E2E MLperf tests for DeepSeek-R1 (no accuracy, 12-decoder layers only)"
     key: test_12
     soft_fail: true
     env:
       NEW_MODEL_DESIGN: "True"
       USE_V6E8_QUEUE: "True"
       SKIP_ACCURACY_TESTS: "True"
       VLLM_MLA_DISABLE: "1"
       JAX_RANDOM_WEIGHTS: "True"
     agents:
       queue: tpu_v6e_8_queue
     commands:
       - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh -m deepseek-ai/DeepSeek-R1-0528

   - label: "lora tests for JAX + vLLM models multi chips"
     key: test_13
     soft_fail: true
     env:
       USE_V6E8_QUEUE: "True"
       VLLM_LOG_LEVEL: "INFO"
     agents:
       queue: tpu_v6e_8_queue
     commands:
       - |
         .buildkite/scripts/run_in_docker.sh \
           bash -c 'MODEL_IMPL_TYPE=vllm TPU_BACKEND_TYPE=jax python3 -m pytest -s -v -x /workspace/tpu_inference/tests/lora/test_lora.py -k multi_lora'


  # -----------------------------------------------------------------
  # NOTIFICATION STEP
  # -----------------------------------------------------------------
   - label: "TPU Test Notification"
     depends_on:
       - test_0
       - test_1
       - test_2
       - test_3
       - test_4
       - test_5
       - test_6
       - test_7
       - test_8
       - test_9
       - test_10
       - test_11
       - test_12
       - test_13
     agents:
       queue: tpu_v6e_queue
     commands:
       - |
         .buildkite/scripts/check_results.sh \
           "TPU JAX Tests Failed" test_0 test_1 test_2 test_3 test_4 test_5 test_6 test_7 test_8 test_9 test_10 test_11 test_12 test_13
