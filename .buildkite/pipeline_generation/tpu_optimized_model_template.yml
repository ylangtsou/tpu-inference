# {MODEL_NAME}
steps:
  - label: "Unit tests for {MODEL_NAME}"
    key: "{SANITIZED_MODEL_NAME}_UnitTest"
    soft_fail: true
    agents:
      queue: {QUEUE}
    commands:
      - echo "placeholder"  # TODO: replace with your unit test command
  - label: "Record unit test result for {MODEL_NAME}"
    key: "record_{SANITIZED_MODEL_NAME}_UnitTest"
    depends_on: "{SANITIZED_MODEL_NAME}_UnitTest"
    env:
      CI_STAGE: "UnitTest"
      CI_TARGET: {MODEL_NAME}
    agents:
      queue: cpu
    commands:
      - |
        .buildkite/scripts/record_step_result.sh {SANITIZED_MODEL_NAME}_UnitTest

  - label: "Integration tests for {MODEL_NAME}"
    key: "{SANITIZED_MODEL_NAME}_IntegrationTest"
    depends_on: "record_{SANITIZED_MODEL_NAME}_UnitTest"
    soft_fail: true
    agents:
      queue: {QUEUE}
    env:
      TEST_MODEL: {MODEL_NAME}
      TENSOR_PARALLEL_SIZE: {TENSOR_PARALLEL_SIZE}
      MINIMUM_ACCURACY_THRESHOLD: 0  # TODO : replace 0 with your accuracy threshold
    commands:
      - |
        .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/test_accuracy.sh
  - label: "Record integration test result for {MODEL_NAME}"
    key: "record_{SANITIZED_MODEL_NAME}_IntegrationTest"
    depends_on: "{SANITIZED_MODEL_NAME}_IntegrationTest"
    env:
      CI_TARGET: {MODEL_NAME}
      CI_STAGE: "IntegrationTest"
    agents:
      queue: cpu
    commands:
      - |
        .buildkite/scripts/record_step_result.sh {SANITIZED_MODEL_NAME}_IntegrationTest

  - label: "Performance benchmarks for {MODEL_NAME}"
    key: "{SANITIZED_MODEL_NAME}_Benchmark"
    depends_on: "record_{SANITIZED_MODEL_NAME}_IntegrationTest"
    soft_fail: true
    agents:
      queue: {QUEUE}
    env:
      TEST_MODEL: {MODEL_NAME}
      TENSOR_PARALLEL_SIZE: {TENSOR_PARALLEL_SIZE}
      MINIMUM_THROUGHPUT_THRESHOLD: 0  # TODO : replace 0 with your performance threshold
    commands:
      - |
        .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/benchmark.sh
  - label: "Record performance benchmark result for {MODEL_NAME}"
    key: "record_{SANITIZED_MODEL_NAME}_Benchmark"
    depends_on: "{SANITIZED_MODEL_NAME}_Benchmark"
    env:
      CI_TARGET: {MODEL_NAME}
      CI_STAGE: "Benchmark"
    agents:
      queue: cpu
    commands:
      - |
        .buildkite/scripts/record_step_result.sh {SANITIZED_MODEL_NAME}_Benchmark
